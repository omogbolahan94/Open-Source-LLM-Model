# DEDICATION
Thanks to DataTalk LLM Zoomcamp for the opportunity to learn and hone my LLM skills.

# REQUIREMENT: CLOUD GPU
GPU is reuqired to build an LLM model and we can get access to them through:
* Google colab
* AWS sagemaker
* Saturn cloud

# ABOUT 
Exploring different open source LLM models. 

The following are the models that can be gotten from huggingface:
* Google flan-t5 model from huggingface.
* Microsoft phi-3 from huggingface. Read about [pphi-3 here](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)
* Mistral-7B-Instruct from huggingface [mistral here](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)
* LLM360/Amber: this model uses LLAMA architecture. Ream more about it [here](https://huggingface.co/LLM360/Amber)

# LLMs PERFORMANCE LEADERBOARD**
* On huggingface, they can be found here: [leaderboards](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
* We can as well google them.
* Utilise chatGPT as well.

# RUNNING LLM MODELS ON CPU
Ollama is an AI-powered platform designed to facilitate the development, deployment, and management of machine learning models and data-driven applications. It offers a range of features and tools to support data scientists, machine learning engineers, and businesses in leveraging AI technology effectively. 
* Set it up: [Ollama Github](https://github.com/ollama/ollama)
* we can run the ollama application on command prompt or on docker.

